{"pages":[{"title":"Papers","text":"Variational Tracking and Prediction with Generative Disentangled State-Space Models Adnan Akhundov, Maximilian Soelch, Justin Bayer, and Patrick van der Smagt (2019) arXiv [ www ] Estimating Fingertip Forces, Torques, and Local Curvatures from Fingernail Images Nutan Chen, Göran Westling, Benoni B. Edin, and Patrick van der Smagt (2019) Robotica [ www ] Early Integration for Movement Modeling in Latent Spaces Rachel Hornung, Nutan Chen, and Patrick van der Smagt (2019) The Handbook of Multimodal-Multisensor Interfaces, Volume 3: Language Processing, Software, Commercialization, and Emerging Directions [ www ] Unsupervised real-time control through variational empowerment Maximilian Karl, Philip Becker-Ehmck, Maximilian Soelch, Djalel Benbouzid, Patrick van der Smagt, and Justin Bayer (2019) International Symposium on Robotics Research (ISRR) [ www ] Learning Hierarchical Priors in VAEs Alexej Klushyn, Nutan Chen, Richard Kurle, Botond Cseke, and Patrick van der Smagt (2019) Conference on Neural Information Processing Systems (NeurIPS) [ www | blog ] Switching Linear Dynamics for Variational Bayes Filtering Philip Becker-Ehmck, Jan Peters, and Patrick van der Smagt (2019) International Conference on Machine Learning (ICML) [ www ] Approximate bayesian inference in spatial environments Atanas Mirchev, Baris Kayalibay, Maximilian Soelch, Patrick van der Smagt, and Justin Bayer (2019) Robotics: Science and Systems (RSS) [ www | blog ] On Deep Set Learning and the Choice of Aggregations Maximilian Soelch, Adnan Akhundov, Patrick van der Smagt, and Justin Bayer (2019) International Conference on Artificial Neural Networks (ICANN) [ www | blog ] Increasing the Generalisation Capacity of Conditional VAEs Alexej Klushyn, Nutan Chen, Botond Cseke, Justin Bayer, and Patrick van der Smagt (2019) International Conference on Artificial Neural Networks (ICANN) [ www ] Fast approximate geodesics for deep generative models Nutan Chen, Francesco Ferroni, Alexej Klushyn, Alexandros Paraschos, Justin Bayer, and Patrick van der Smagt (2019) International Conference on Artificial Neural Networks (ICANN) [ www | blog ] Bayesian learning of neural network architectures Georgi Dikov, Patrick van der Smagt, and Justin Bayer (2019) International Conference on Artificial Intelligence and Statistics (AISTATS) [ www | blog ] Orc—a lightweight, lightning-fast middleware Felix Frank, Alexandros Paraschos, and Patrick van der Smagt (2019) IEEE International Conference on Robotic Computing (IRC) [ www ] Multi-source neural variational inference Richard Kurle, Stephan Guennemann, and Patrick van der Smagt (2018) AAAI Conference on Artficial Intelligence [ www ] Active learning based on data uncertainty and model sensitivity Nutan Chen, Alexej Klushyn, Alexandros Paraschos, Djalel Benbouzid, and Patrick van der Smagt (2018) International Conference on Intelligent Robots and Systems (IROS) [ www | blog ] Metrics for deep generative models Nutan Chen, Alexej Klushyn, Richard Kurle, Xueyan Jiang, Justin Bayer, and Patrick van der Smagt (2018) International Conference on Artificial Intelligence and Statistics (AISTATS) [ www | blog ] CNN-based segmentation of medical imaging data Baris Kayalibay, Grady Jensen, and Patrick van der Smagt (2017) arXiv [ www ] Deep variational Bayes filters: unsupervised learning of state space models from raw data Maximilian Karl, Maximilian Soelch, Justin Bayer, and Patrick van der Smagt (2017) International Conference on Learning Representations (ICLR) [ www | blog ] Dynamic movement primitives in latent space of time-dependent variational autoencoders Nutan Chen, Maximilian Karl, and Patrick van der Smagt (2016) International Conference on Humanoid Robots (Humanoids) [ www ] Previous publications","tags":"pages","url":"https://argmax.ai/papers"},{"title":"Learning Hierarchical Priors in VAEs","text":"Variational autoencoders (VAEs) (Kingma and Welling, 2013) , (Rezende et al., 2014) are a class of probabilistic latent-variable models for unsupervised learning and one of the models we base our work on. The idea behind the VAE is that the learned probabilistic model and the corresponding (approximate) posterior distribution of the latent variables provide a decoder/encoder pair that can capture semantically meaningful features of the data. In this blog post, we address the issue of learning informative latent representations/encodings. In classifiable data, this may be representations that cluster according to some discrete features of the data. In regression data, important variations in data should be aligned with the axes of the latent space. The latent representation in a VAE is strongly influenced by the prior on those latent variables. In the vanilla VAE, this prior is a standard normal distribution. This can be a limiting factor because it leads to over-regularising the posterior distribution, resulting in latent representations that do not represent well the structure of the data (Alemi et al., 2018) . Several methods have been proposed to alleviate this problem, including: using specialised optimisation algorithms that try to find local/global minima of the training objective that correspond to informative latent representations (Bowman et al., 2016) , (Sonderby et al., 2016) , (Higgins et al., 2017) , (Rezende and Viola, 2018) ; or defining and learning complex prior distributions that can better model the encoded data manifold (Chen et al., 2016) , (Tomczak and Welling, 2018) . In the following, we will introduce a combination of these two approaches. Background: Variational Autoencoders VAEs are a class of unsupervised learning methods, where we assume that the data \\(\\mathbf{x}\\in \\mathbb{R}&#94;n\\) is generated by the probabilistic model $$ \\begin{align} p_{\\theta}(\\mathbf{x}) = \\int\\! p_{\\theta}(\\mathbf{x} \\vert\\mathbf{z})\\, p(\\mathbf{z})\\, \\mathrm{d}\\mathbf{z}, \\end{align} $$ and the data \\(\\mathcal{D} = \\{\\mathbf{x}_i\\}_{i=1}&#94;N\\) is a set of identically distributed and independently generated data points. The model parameters \\(\\theta\\) are learned through amortised variational EM, which requires learning an approximate posterior distribution \\(q_{\\phi}(\\mathbf{z} \\vert \\mathbf{x}_i) \\approx p_{\\theta}(\\mathbf{z} \\vert \\mathbf{x}_i)\\) . It is hoped that the learned \\(q_{\\phi}(\\mathbf{z} \\vert \\mathbf{x})\\) and \\(p_{\\theta}(\\mathbf{x} \\vert \\mathbf{z})\\) result in an informative latent representation of the data. For example, \\(\\{\\mathbb{E}_{q_{\\theta}(\\mathbf{z} \\vert \\mathbf{x}_i)}[\\mathbf{z}]\\}_{i=1}&#94;N\\) cluster w.r.t. some discrete features or important factors of variation in the data, which often lie along the axes (up to some rotation or linear transformation): The VAE is trained by minimising the evidence lower bound (ELBO) (Kingma and Welling, 2013) , (Rezende et al., 2014) $$ \\begin{align} \\mathbb{E}_{p_\\mathcal{D}(\\mathbf{x})} \\big[ \\log p_{\\theta}(\\mathbf{x}) \\big] \\geq \\mathcal{F}_\\text{ELBO}(\\theta, \\phi) \\equiv \\mathop{\\mathbb{E}_{p_\\mathcal{D}(\\mathbf{x})}} \\Big[ \\underbrace{ \\mathbb{E}_{q_\\phi(\\mathbf{z}\\vert\\mathbf{x})} \\big[ \\log p_\\theta(\\mathbf{x}\\vert\\mathbf{z}) \\big] }_{ \\mathrm{reconstruction} } - \\underbrace{ \\mathrm{KL} \\big( q_\\phi(\\mathbf{z}\\vert\\mathbf{x})\\|\\,p(\\mathbf{z}) \\big) }_{ \\mathrm{KL~divergence} } \\Big], \\end{align} $$ where \\(q_{\\phi}(\\mathbf{z}\\vert\\mathbf{x})\\) and \\(p_\\theta(\\mathbf{x}\\vert\\mathbf{z})\\) are typically assumed to be diagonal Gaussians with their parameters defined as neural network functions of the conditioning variables, and \\({p_\\mathcal{D}(\\mathbf{x})=\\frac{1}{N}\\sum_{i=1}&#94;{N}\\delta(\\mathbf{x}-\\mathbf{x}_i)}\\) refers to the empirical distribution of the data \\(\\mathcal{D}\\) . Variational Autoencoders as a constrained optimisation problem First of all: why constrained optimisation? The advantage of constrained optimisation is that it allows us to introduce conditions, which have to be fulfilled when optimising an objective function. In the context of VAEs, this can become especially important when it comes to complicated neural network architectures or hierarchical graphical models (Sonderby et al., 2016) . The reason is: a low KL divergence is useless if the reconstruction fails. We therefore want to control the reconstruction quality. To achieve this, Rezende and Viola (2018) proposed to formulate the learning problem as $$ \\begin{align} \\min_\\phi \\, \\underbrace{ \\mathbb{E}_{p_\\mathcal{D}(\\mathbf{x})} \\big[ \\mathop{\\mathrm{KL} \\big( q_\\phi(\\mathbf{z}\\vert\\mathbf{x})\\|\\,p(\\mathbf{z}) \\big)} \\big] }_{ \\mathrm{optimisation~objective} } \\quad \\mathrm{s.t.} \\quad \\underbrace{ \\mathop{\\mathbb{E}_{p_\\mathcal{D}(\\mathbf{x})}} \\mathbb{E}_{q_\\phi(\\mathbf{z}\\vert\\mathbf{x})} \\big[ \\text{C}_\\theta(\\mathbf{x}, \\mathbf{z}) \\big] \\leq \\kappa&#94;2 }_{ \\mathrm{inequality~constraint} }. \\end{align} $$ \\({\\text{C}_\\theta(\\mathbf{x}, \\mathbf{z})}\\) is defined as the reconstruction error-related term in \\({-\\log p_\\theta(\\mathbf{x}\\vert\\mathbf{z})}\\) . Thus, requiring the average reconstruction error to be lower or equal than \\(\\kappa&#94;2\\) . For example, in case of fitting continuous data, the reconstruction error is the quadratic loss \\(\\text{C}_\\theta(\\mathbf{x}, \\mathbf{z})=\\vert\\vert \\mathbf{x}- g_\\theta (\\mathbf{z})\\vert\\vert&#94;2\\) corresponding to a nonlinear conditional Gaussian likelihood model. The function \\(g_\\theta (\\mathbf{z})\\) is the decoder mapping the latent space into the data space. The Lagrangian corresponding to the above optimisation problem is $$ \\begin{align} \\mathcal{L}(\\theta, \\phi; \\lambda) \\equiv \\mathop{\\mathbb{E}_{p_\\mathcal{D}(\\mathbf{x})}} \\Big[ \\mathrm{KL} \\big( q_\\phi(\\mathbf{z}\\vert\\mathbf{x})\\|\\,p(\\mathbf{z}) \\big) + \\lambda \\big( \\mathop{\\mathbb{E}_{q_\\phi(\\mathbf{z}\\vert\\mathbf{x})}} \\big[ \\text{C}_\\theta(\\mathbf{x}, \\mathbf{z}) \\big] - \\kappa&#94;2 \\big) \\Big], \\end{align} $$ and the learning is formulated as a saddle point optimisation of \\(\\mathcal{L}(\\theta, \\phi; \\lambda)\\) w.r.t. \\((\\theta, \\phi)\\) and \\(\\lambda\\) . The main difference between \\(\\mathcal{L}(\\theta, \\phi; \\lambda)\\) and \\(\\mathcal{F}_\\text{ELBO}(\\theta, \\phi)\\) is the Lagrange multiplier \\(\\lambda\\) , which weights the inequality constraint. However, in general \\(\\mathcal{L}(\\theta, \\phi; \\lambda)\\) can only be guaranteed to be the ELBO if \\(\\lambda=1\\) , or in case of \\(0\\leq\\lambda<1\\) , a scaled lower bound on the ELBO. Note: in the classical constrained optimisation setting, constraints are not part of the objective function, and hence \\(\\theta\\) would not be optimised. Otherwise, the convexity of the optimisation problem cannot be guaranteed. Let's go a few steps back to resolve this lack of clarity: within the VAE framework, it is a common practice to optimise ( \\(\\theta, \\phi\\) ) jointly. The original (EM) optimisation problem (e.g. (Neal and Hinton, 1998) ), however, is formulated as $$ \\begin{align} \\min_{\\theta,\\phi} -\\mathcal{F}_\\text{ELBO}(\\theta,\\phi) \\: \\widehat{=} \\, \\min_{\\theta} \\min_{\\phi} -\\mathcal{F}_\\text{ELBO}(\\theta, \\phi). \\end{align} $$ This perspective allows us to interpret the optimisation problem as a sequence of Lagrangians: $$ \\begin{align} \\overbrace{ \\min_{\\theta} }&#94;{ \\mathrm{M\\text{-}step} } \\:\\: \\underbrace{ \\max_{\\lambda} \\, \\min_{\\phi} }_{ \\mathrm{E\\text{-}step} } \\:\\:\\: \\mathcal{L}(\\theta, \\phi; \\lambda) \\quad \\text{s.t.} \\quad \\lambda \\geq 0, \\end{align} $$ where \\(\\min_{\\theta}\\) and \\({\\max_{\\lambda} \\min_{\\phi} \\mathcal{L}(\\theta, \\phi; \\lambda)}\\) can be viewed as the corresponding steps of the original EM algorithm for training VAEs. Hierarchical priors for learning informative latent representations As the next step, we introduce an empirical Bayes prior within the above constrained optimisation setting. Referring to the argument in the beginning, such flexible priors avoid over-regularising the posterior distribution, and hence allow to incentivise the learning of informative latent representations. It has been shown that the optimal empirical Bayes prior is the aggregated posterior distribution \\(p&#94;{\\ast}(\\mathbf{z}) = \\mathbb{E}_{p_{\\mathcal{D}}(\\mathbf{x})}\\big[q_{\\phi}(\\mathbf{z}\\vert\\mathbf{x})\\big]\\) (Tomczak and Welling, 2018) . In order to express \\(p&#94;{\\ast}(\\mathbf{z})\\) , we use a continuous mixture/hierarchical model $$ \\begin{align} p_\\Theta(\\mathbf{z}) = \\int\\! p_\\Theta(\\mathbf{z}\\vert \\mathbf{\\zeta})\\, p(\\mathbf{\\zeta})\\, \\mathrm{d}\\mathbf{\\zeta} \\end{align} $$ and learn the parameters by applying an importance-weighted lower bound (Burda et al., 2015) on $$ \\begin{align} \\mathbb{E}_{p&#94;{\\ast}(\\mathbf{z})} \\big[ \\log p(\\mathbf{z}) \\big] = \\mathbb{E}_{p_\\mathcal{D}(\\mathbf{x})} \\mathop{\\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x})}} \\big[ \\log p(\\mathbf{z}) \\big] \\geq \\mathbb{E}_{p_\\mathcal{D}(\\mathbf{x})} \\mathop{\\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x})}} \\big[ \\mathop{\\mathcal{L}_\\text{IW}(\\Theta, \\Phi; \\mathbf{z})} \\big]. \\end{align} $$ This introduces a new optimisation objective $$ \\begin{align} \\mathbb{E}&_{p_\\mathcal{D}(\\mathbf{x})} \\big[ \\mathop{\\mathrm{KL} \\big( q_\\phi(\\mathbf{z}\\vert\\mathbf{x})\\|\\,p_\\Theta(\\mathbf{z}) \\big)} \\big] \\leq \\mathbb{E}_{p_\\mathcal{D}(\\mathbf{x})} \\big[ \\mathop{\\mathcal{F}(\\phi, \\Theta, \\Phi; \\mathbf{x})} \\big] \\\\ &\\equiv \\mathbb{E}_{p_\\mathcal{D}(\\mathbf{x})} \\mathop{\\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x})}} \\bigg[ \\log q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) - \\underbrace{ \\mathop{\\mathbb{E}_{\\mathbf{\\zeta}_{1:K}\\sim q_\\Phi(\\mathbf{\\zeta}|\\mathbf{z})}} \\Big[ \\log\\frac{1}{K}\\sum_{k=1}&#94;{K}\\frac{p_\\Theta(\\mathbf{z},\\mathbf{\\zeta}_k)}{q_\\Phi(\\mathbf{\\zeta}_k\\vert\\mathbf{z})} \\Big] }_{ \\mathcal{L}_\\text{IW}(\\Theta, \\Phi; \\mathbf{z}) } \\bigg], \\end{align} $$ where \\(p(\\mathbf{\\zeta})\\) is a standard normal distribution and \\(K\\) the number of importance weights. We refer to this approach as variational hierarchical prior (VHP). As a result, we arrive at the Lagrangian $$ \\begin{align} \\mathcal{L}_\\text{VHP}(\\theta, \\phi, \\Theta, \\Phi; \\lambda) \\equiv \\mathop{\\mathbb{E}_{p_\\mathcal{D}(\\mathbf{x})}} \\Big[ \\mathop{\\mathcal{F}(\\phi, \\Theta, \\Phi; \\mathbf{x})} + \\lambda \\big( \\mathop{\\mathbb{E}_{q_\\phi(\\mathbf{z}\\vert\\mathbf{x})}} \\big[ \\text{C}_\\theta(\\mathbf{x}, \\mathbf{z}) \\big] - \\kappa&#94;2 \\big) \\Big]. \\end{align} $$ The constrained optimisation problem is formulated as $$ \\begin{align} \\underbrace{ \\min_{\\Theta, \\Phi} }_{ {\\substack{\\mathrm{empirical}\\\\ \\mathrm{Bayes}}} } \\overbrace{ \\min_{\\theta} }&#94;{ \\mathrm{M\\text{-}step} } \\:\\:\\, \\underbrace{ \\max_{\\lambda} \\, \\min_{\\phi} }_{ \\mathrm{E\\text{-}step} } \\:\\:\\: \\mathcal{L}_\\text{VHP}(\\theta, \\phi, \\Theta, \\Phi; \\lambda) \\quad \\text{s.t.} \\quad \\lambda \\geq 0, \\end{align} $$ which leads to the following double-loop method: in the outer loop we update the upper bound (empirical Bayes) w.r.t. \\((\\Theta, \\Phi)\\) ; in the inner loop we solve the original constrained optimisation problem w.r.t. \\({(\\theta, \\lambda, \\phi)}\\) . The Lagrange multiplier \\(\\lambda\\) is updated by a quasi-gradient ascent. The update step is defined so that it finishes at \\(\\lambda = 1\\) , in order to optimise the ELBO at the end of the training. For more details regarding the \\(\\lambda\\) update scheme and the optimisation algorithm, we would like to refer to our paper which is published at NeurIPS 2019. Our proposed method, which is a combination of an ELBO-like Lagrangian and an importance-weighted bound on the optimal empirical Bayes log-prior distribution, can be interpreted as follows: the posterior of the first stochastic layer \\(q_\\phi(\\mathbf{z}|\\mathbf{x})\\) can learn an informative latent representation due to the flexible prior; in order to express the flexible prior, we use a hierarchical mode and learn the parameters by applying an importance-weighted lower bound on \\(\\mathbb{E}_{p&#94;{\\ast}(\\mathbf{z})} \\big[\\log p(\\mathbf{z})\\big]\\) . Despite a diagonal Gaussian \\(q_\\Phi(\\mathbf{\\zeta}\\vert \\mathbf{z})\\) , the importance weighting allows to learn a precise conditional \\(p_\\Theta(\\mathbf{z}\\vert\\mathbf{\\zeta})\\) from the standard normal distribution \\(p(\\mathbf{\\zeta})\\) to the aggregated posterior \\(\\mathbb{E}_{p_{\\mathcal{D}}(\\mathbf{x})}[q_{\\phi}(\\mathbf{z}\\vert\\mathbf{x})]\\) (Cremer et al., 2017) . Alternatively, one could use, for example, normalising flows (Rezende and Mohamed, 2015) . Otherwise, the hierarchical prior might be not expressive enough and the model could compensate that by regularising \\(q_\\phi(\\mathbf{z}|\\mathbf{x})\\) . This would result in a restricted latent representation. Comparison to Variational Autoencoders with standard Normal priors Our key reason to introduce hierarchical priors was to get an informative latent representation. But does it work? To verify the quality of the latent representations, we build on the manifold hypothesis (Rifai et al., 2011) . The idea can be summarised by the following assumption: real-world data presented in high-dimensional spaces is likely to concentrate close to nonlinear sub-manifolds of much lower dimensionality. Following this hypothesis, the quality of latent representations can be evaluated by interpolating between data points along the learned data manifold in the latent space—and reconstructing this path to the observable space. To verify the above assumption, we use a k-NN graph, which is built based on samples from the (learned) prior—hence, based on the learned latent representation—with edge weights that are Euclidean distances in the latent space between the related node pairs. To find the shortest path through the graph we use \\(A&#94;\\star\\) , a classic search algorithm. In the following, we compare our method (VHP-VAE) to IWAE (Burda et al., 2015) a state-of-the-art method within the VAE framework that uses a standard normal prior. CMU Human Motion Data First, let's have a look at the learned latent representation of five different human motions based on the CMU Graphics Lab Motion Capture Database . This dataset is especially well suited for visualisations since it is simple enough for a two-dimensional latent space. The k-NN graphs are built based on samples from the respective (learned) prior distributions. The bluescale indicates the edge weight and the coloured lines represent four human-movement interpolations between different poses. In case of the VHP-VAE, the latent representations of different movements are separated. By contrast, the IWAE cannot represent the different motions separately in the latent space since it is restricted by the standard normal prior. Reconstructing the above interpolations leads to the following human movements: We marked discontinuities in the movements by blue boxes. Note that the VHP-VAE leads to smoother interpolations, whereas the IWAE interpolations show quite a few abrupt changes in the movements due to the missing structure in the latent space. 3D faces How does the method scale to more complex data? To validate this, we show a small experiment on 3D faces (Paysan et al., 2009) . In this case, the latent space is 32-dimensional: Final words In this blog post, we have seen that the learned hierarchical prior is indeed nontrivial, moreover, it is well-adapted to the latent representation, reflecting the topology of the encoded data manifold. The method provides informative latent representations and performs particularly well on data, where the relevant features change continuously. This work was published (spotlight) at the Conference on Neural Information Processing Systems (NeurIPS), 2019 [preprint] if (!document.getElementById('mathjaxscript_pelican_#%&#64;#$&#64;#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%&#64;#$&#64;#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); } Bibliography Alexander A Alemi, Ben Poole, Ian Fischer, Joshua V Dillon, Rif A Saurous, and Kevin Murphy. Fixing a broken ELBO . ICML , 2018. ↩ Samuel R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and Samy Bengio. Generating sentences from a continuous space. CoNLL , 2016. ↩ Yuri Burda, Roger B. Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. CoRR , 2015. ↩ 1 2 Xi Chen, Diederik P. Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John Schulman, Ilya Sutskever, and Pieter Abbeel. Variational lossy autoencoder. CoRR , 2016. ↩ Chris Cremer, Quaid Morris, and David Duvenaud. Reinterpreting importance-weighted autoencoders. arXiv:1704.02916 , 2017. ↩ Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. Beta-VAE: Learning basic visual concepts with a constrained variational framework . ICLR , 2017. ↩ Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. CoRR , 2013. ↩ 1 2 Radford M Neal and Geoffrey E Hinton. A view of the em algorithm that justifies incremental, sparse, and other variants. In Learning in graphical models . 1998. ↩ P. Paysan, R. Knothe, B. Amberg, S. Romdhani, and T. Vetter. A 3d face model for pose and illumination invariant face recognition. AVSS , 2009. ↩ Danilo Jimenez Rezende and Shakir Mohamed. Variational inference with normalizing flows. ICML , 2015. ↩ Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. In Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32 , ICML'14, II–1278–II–1286. JMLR.org, 2014. URL: http://dl.acm.org/citation.cfm?id=3044805.3045035 . ↩ 1 2 Danilo Jimenez Rezende and Fabio Viola. Taming VAEs . arXiv:1810.00597 , 2018. ↩ 1 2 Salah Rifai, Yann N Dauphin, Pascal Vincent, Yoshua Bengio, and Xavier Muller. The manifold tangent classifier. NeurIPS , 2011. ↩ Casper Kaae S ø nderby, Tapani Raiko, Lars Maal ø e, S ø ren Kaae S ø nderby, and Ole Winther. Ladder variational autoencoders. NeurIPS , 2016. ↩ 1 2 Jakub Tomczak and Max Welling. VAE with a VampPrior . AISTATS , 2018. ↩ 1 2","tags":"blog","url":"https://argmax.ai/blog/vhp-vae/"},{"title":"Oliver Brock - 2019-12-13","text":"Title Deep Learning and Morphological Computation: Friends or Foes? Abstract AI is currently seen as equivalent to deep learning. Is that justified? Can deep learning really solve AI? That probably depends importantly on what we mean by AI. In this talk, I will argue that to produce \"real\" AI (whatever that is), we will have to leverage different types of computation, not just deep learning. For each of these types, of which morphological computation is another one, we have to learn how to encode appropriate priors to make computation effective, robust, and general for a particular type of problem. I will give several examples from our research to support my arguments. Photo credit: Lip Kee Yap ( CC BY-SA 2.0 ) About the speaker Oliver Brock is the Alexander-von-Humboldt Professor of Robotics in the School of Electrical Engineering and Computer Science at Technische Universität Berlin, a German \"University of Excellence\". He received his Ph.D. from Stanford University in 2000 and held post-doctoral positions at Rice University and Stanford University. He was an Assistant and Associate Professor in the Department of Computer Science at the University of Massachusetts Amherst before to moving back to Berlin in 2009. The research of Brock's lab, the Robotics and Biology Laboratory, focuses on robot intelligence, mobile manipulation, interactive perception, grasping, manipulation, soft material robotics, interactive machine learning, deep learning, motion generation, and the application of algorithms and concepts from robotics to computational problems in structural molecular biology. Oliver Brock directs the Research Center of Excellence \"Science of Intelligence\". He is an IEEE Fellow and was president of the Robotics: Science and Systems Foundation from 2012 until 2019.","tags":"talks","url":"https://argmax.ai/talks/brock/"},{"title":"How to Learn Functions on Sets with Neural Networks","text":"In this post we look into functions on sets , and how to learn them with the help of neural networks. As it turns out, set-valued inputs pose unique challenges to our neural architectures, so let us begin by trying to understand the fundamental differences. In your common machine-learning task, you are given a data set \\(\\mathcal D\\) . Your data set may contain pairs of inputs \\(x_i \\in \\mathcal X\\) and outputs \\(y_i \\in \\mathcal Y\\) . Part of the popularity of neural networks is that they excel in adapting to a huge variety of input domains \\(\\mathcal X\\) . In this, there is an implicit assumption so common that we hardly question it in a generic neural application: all inputs \\(x_i\\) should have the same fixed size, e.g., a vector from some space \\(\\mathbb R&#94;d\\) . Set-valued inputs do not allow for that. Each input is a set—which we will call population . The elements of a population—its particles —have a fixed size, but the entire population size may vary. Feed-forward neural networks, expecting fixed-size input, are not equipped for this task. There is, however, a class of neural networks than can handle variable-length inputs: recurrent nets. By interpreting a population as a sequence of particles, we could make use of RNNs to process set-valued. Unfortunately, this ignores a fundamental property of sets: they are unordered. To process them with RNNs, we have to impose some (likely arbitrary) order on the set. As Vinyals et al. (2015) have shown, the output of the RNN is highly dependent on the order of inputs. This is undesirable for proper functions on sets. In short, we are looking for a learnable architecture that is able to process input populations of variable size, and produces outputs invariant to any particular order of the particles in the population. Interestingly, it has been shown ( Zaheer et al. (2017) , refined by Wagstaff et al. (2019) ) that a set function \\(f\\) , under mild assumptions, can be decomposed as $$ f(\\mathcal X) = \\rho\\left(\\sum_{x\\in X} \\phi(x)\\right). $$ Let us take this apart. Any invariant function can be constructed using the same simple recipe: embed each particle individually with \\(\\phi\\) , aggregate the embeddings into an invariant, fixed-size description of the set by summing the embeddings, and then process the aggregate description with \\(\\rho\\) . The generic architecture is depicted below: The basic Deep Sets architecture for set functions: embed a population X into memory M , aggregate the memory into a , process a to obtain the final result r . In this formulation, neither \\(\\phi\\) nor \\(\\rho\\) operate on a set. This immediately allows us to plug in function approximators like neural networks for both—a neural architecture that is invariant by design, the Deep Sets framework. Let us take a closer look at the aggregation step. It is interesting from at least two perspectives: on the one hand, it is the crucial step for inducing invariance to any ordering of the particles in the population. The summation negates the identities of individual particles. On the other hand, despite its importance, and despite seeing alternatives like mean or max being used instead of summation in the literature, it is the only non-learnable part in the Deep Sets framework. Our Contributions In our paper On Deep Set Learning and the Choice of Aggregations (Soelch et al., 2019) , we examine its role in more depth. On the theoretical side, we show that a broader class of aggregation functions are also applicable without breaking the theoretical decomposition result, for example mean or also logsumexp . We call this class of functions sum-isomorphic , because they act like a sum in a space isomorphic to \\(\\mathcal X\\) . This is interesting because they are numerically favorable over sum: their result does not scale linearly with the number of set elements. For mean aggregations, the activation will be on the same order of magnitude across any population size. A particular case can be made for logsumexp, as it exhibits diminishing returns : the gain from an additional particle diminishes with increasing population size. Moreover, depending on the scale of inputs, logsumexp can behave more like a linear function (for smaller values) or like max (for larger values). Moreover, we suggest recurrent, learnable aggregations , an aggregation function inspired by the architecture suggested by Vinyals et al. (2015) . The idea is to learn an aggregation that dynamically queries the particle embeddings. Each subsequent query \\(q_t\\) depends on the response \\(a_{t-1}\\) of the embeddings to the previous query \\(q_{t-1}\\) . This procedure is depicted below. A learnable, recurrent aggregation function. The recurrent cell implements a loop of queries q and responses a to the embedded memory M . Since each query-response cycle is invariant, the overall procedure is invariant. Lastly, we process all responses in backward order, so that the first query and its response have the most immediate effect on the result of the recurrent aggregation. On the empirical side, across a number of different experiments, we find a number of interesting results to be considered in future experiments on set-valued inputs: Aggregation functions matter: the choice of aggregation function, even if not learned, can have a crucial impact on the overall performance. The application matters: which aggregation function to use largely depends on the task at hand. As a general guideline, we found that classification tasks benefit from using max-aggregation, while smoother aggregations tended to work significantly better for regression tasks. The population size is understudied: for simplicity, Deep Sets networks are often trained with a fixed population size. We found that this can lead to overfitting for populations of that particular size, and much decreased performance for both smaller and larger populations. In a typical application, where the population size may vary at inference time, a more desired behavior would be a monotonic increase of performance in the population size, akin to asymptotic consistency of statistical estimators. Learnable aggregations can make your model more robust to such effects. We are only beginning to understand the design and learning process of neural set architectures. Our paper will help you selecting appropriate aggregation functions by offering a wider selection of applicable aggregations and empirical results to inform the decision. This work was published at the International Conference on Artificial Neural Networks (ICANN), 2019, in Munich. We refer to the paper for a more detailed discussion: DOI , preprint . if (!document.getElementById('mathjaxscript_pelican_#%&#64;#$&#64;#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%&#64;#$&#64;#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); } Bibliography Maximilian Soelch, Adnan Akhundov, Patrick van der Smagt , and Justin Bayer. On Deep Set Learning and the Choice of Aggregations . In Igor V. Tetko, V ě ra K ů rkov á , Pavel Karpov, and Fabian Theis, editors, Artificial Neural Networks and Machine Learning – ICANN 2019: Theoretical Neural Computation , Lecture Notes in Computer Science , 444–457. Springer International Publishing , 2019. URL: https://arxiv.org/abs/1903.07348 . ↩ Oriol Vinyals, Samy Bengio, and Manjunath Kudlur. Order Matters : Sequence to sequence for sets. arXiv:1511.06391 [cs, stat] , November 2015. URL: http://arxiv.org/abs/1511.06391 , arXiv:1511.06391 . ↩ 1 2 Edward Wagstaff, Fabian B. Fuchs, Martin Engelcke, Ingmar Posner, and Michael Osborne. On the Limitations of Representing Functions on Sets . arXiv:1901.09006 [cs, stat] , January 2019. URL: http://arxiv.org/abs/1901.09006 , arXiv:1901.09006 . ↩ Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan R Salakhutdinov, and Alexander J Smola. Deep Sets . In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30 , pages 3391–3401. Curran Associates, Inc. , 2017. URL: http://papers.nips.cc/paper/6931-deep-sets.pdf . ↩","tags":"blog","url":"https://argmax.ai/blog/setinvariance/"},{"title":"Approximate Geodesics for Deep Generative Models","text":"Neural samplers such as variational autoencoders (VAEs) or generative adversarial networks (GANs) approximate distributions by transforming samples from a simple random source—the latent space—to a more complex distribution—corresponding to the distribution from which is data is sampled. Typically, the data set is sparse, while the latent space is compact. Consequently, points that are separated by low-density regions in observation space will be pushed together in latent space, and the spaces get distored. In effect, stationary distances in the latent space are poor proxies for similarity in the observation space. How can this be solved? We transfer ideas from Riemannian geometry to this setting, letting the distance between two points be the shortest path on a Riemannian manifold induced by the transformation. The method yields a principled distance measure, provides a tool for visual inspection of deep generative models, and an alternative to linear interpolation in latent space. Riemannian geometry for generative models Our model is based on the importance-weighted autoencoder (IWAE), but can be used for any generative model. In the IWAE, the observable data \\(\\mathbf{x} \\in \\mathbb{R}&#94;{N_{x}}\\) are represented through latent variables \\(\\mathbf{z} \\in \\mathbb{R}&#94;{N_{z}}\\) , that are based on hidden characteristics in \\(\\mathbf{x}\\) . A Riemannian space is a differentiable manifold \\(M\\) with an additional metric to describe its geometric properties. This enables assigning an inner product in the tangent space at each point \\(\\mathbf{z}\\) in the latent space through the corresponding metric tensor \\(\\mathbf{G} \\in \\mathbb{R}&#94;{N_z \\times N_z}\\) , i.e., $$ \\langle \\mathbf{z}', \\mathbf{z}'\\rangle_{\\mathbf{z}} := \\mathbf{z}'&#94;{T}\\, \\mathbf{G}(\\mathbf{z})\\, \\mathbf{z}' $$ with \\(\\mathbf{z}' \\in T_{\\mathbf{z}}M\\) and \\(\\mathbf{z} \\in M\\) . \\(T_{\\mathbf{z}}M\\) is the tangent space. Treating the latent space of a VAE as a Riemannian manifold allows us to compute the observation space distance of latent variables. Assuming we have a trajectory \\(\\gamma:[0, 1]\\rightarrow\\mathbb{R}&#94;{N_{z}}\\) in the Riemannian (latent) space that is transformed by a continuous function \\(f(\\gamma(t))\\) (decoder) to an \\(N_{x}\\) -dimensional Euclidean (observation) space. The length of this trajectory in the observation space, referred to as the Riemannian distance, is defined by $$ \\begin{align} L(\\gamma)&\\equiv\\int_0&#94;1 \\left\\| \\frac{\\partial f(\\gamma(t))}{\\partial t}\\right\\| \\mathrm{d}t = \\int_0&#94;1 \\left\\| \\frac{\\partial f(\\gamma(t))}{\\partial \\gamma(t)} \\frac{\\partial \\gamma(t)}{\\partial t} \\right\\| \\mathrm{d}t =\\int_0&#94;1 \\left\\| \\mathbf{J} \\frac{\\partial \\gamma(t)}{\\partial t} \\right\\| \\mathrm{d}t, \\end{align} $$ with \\(\\dot{\\gamma}(t)\\) denoting the time-derivative of the trajectory. \\(\\sqrt{\\big<\\gamma'(t), \\gamma'(t)\\big>_{\\gamma(t)}}\\) is the Riemannian velocity \\(\\phi(t)\\) . The metric tensor is defined as \\(\\mathbf{G}=\\mathbf{J}&#94;{T}\\mathbf{J}\\) , with \\(\\mathbf{J}\\) as the Jacobian of the decoder. The trajectory which minimises the Riemannian distance \\(L(\\gamma)\\) is referred to as the shortest path geodesic. We integrate the metric tensor with \\(n\\) equidistantly spaced sampling points along \\(\\gamma\\) to approximate the distance, i.e., $$ \\tilde L(\\gamma) \\approx \\frac{1}{n}\\sum&#94;n_{i=1} \\phi(t_i). $$ We use the magnification factor (MF) to show the sensitivity of the generative models in 2D latent space and evaluate the approximated geodesic. The \\(\\text{MF}(\\mathbf{z})\\equiv \\sqrt{\\det\\mathbf{G}(\\mathbf{z})}\\) can be interpreted as the scaling factor when moving from the Riemannian (latent) to the Euclidean (observation) space, due to the change of variables. Approximate geodesics We proposed two approaches to approximate geodesics—neural network-based and graph-based approaches. Neural network-based geodesics As written in Chen et al. (2018) , we use a neural network \\(g_{\\omega}:\\mathbb{R} \\rightarrow \\mathbb{R}&#94;{N_{z}}\\) to approximate the curve \\(\\gamma\\) in the latent space, where \\(\\omega\\) are the weights and biases. With the start and end points of the curve in the latent space given as \\(\\mathbf{z}_0\\) and \\(\\mathbf{z}_1\\) , we consider the following constrained optimisation problem: $$ \\begin{align} \\min_{\\omega} \\ & L(g_{\\omega}(t)) \\nonumber \\\\ s.t. \\ & g_{\\omega}(0) = \\mathbf{z}_{0}, \\ g_{\\omega}(1) = \\mathbf{z}_{1}. \\end{align} $$ There is an example of showing the difference between the geodesic and Euclidean interpolant using CMU human motion dataset: Graph-based geodesics There are several challenges of the NN-based or similar (e.g., ODE) approaches: it needs the second derivative of the decoder during the optimisation process; it scales poorly with the dimensionality of the observable and the latent space; computing the second derivative limits the selection of the neural network's activation function. To bypass these hurdles we introduce a graph-based approach Chen et al. (2019) , where a discrete and finite graph is built in the latent space using a binary tree data structure, a k-d tree, with edge weights based on Riemannian distances. Once the graph has been built, geodesics can be approximated by applying a classic search algorithm, \\(\\mathrm{A}&#94;\\star\\) . Building the graph. The graph is structured as a k-d tree, a special case of binary space partitioning trees, where each leaf node corresponds to a k-dimensional vector. The nodes of the graph are obtained by encoding the observable data \\(\\mathbf{X} = \\{ \\mathbf{x}&#94;{(1)},\\dots,\\mathbf{x}&#94;{(N)} \\}\\) into their latent representations \\(\\mathbf{z}&#94;{(i)}\\) . This is done by using the respective mean values of the approximate posterior \\(q_{\\phi}(\\mathbf{z}&#94;{(i)}|\\mathbf{x}&#94;{(i)})\\) . Each node is connected by an undirected edge to its k-nearest neighbours. The edge weights are set to Riemannian distances \\(L(\\gamma)\\) , where \\(\\gamma\\) is the straight line between the related pair of nodes. Approximating geodesics. A classic graph-traversing method to obtain the shortest path between nodes is \\(\\mathrm{A}&#94;\\star\\) search. It is an iterative algorithm that, given a graph \\(\\mathcal{G}\\) , maintains a sorted list of nodes that can be visited in the current state. The list is typically initialised with the starting node and is being sorted according to the estimated cost of including node \\(n\\) into the optimal path. The estimated cost is computed by \\(f(n) = g(n) + h(n),\\) where \\(g(n)\\) is the cost of the path from the starting node \\(n_\\mathrm{start}\\) to \\(n\\) and \\(h(n)\\) is a heuristic function that estimates the remaining cost from \\(n\\) to the target node \\(n_\\mathrm{target}\\) . There is an example of showing the difference between the geodesic and Euclidean interpolant using the chair dataset: Applied to robot active learning Our method is applied to robot motion generation and active learning. See more details in Chen et al. (2018) . if (!document.getElementById('mathjaxscript_pelican_#%&#64;#$&#64;#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%&#64;#$&#64;#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); } Bibliography Nutan Chen, Francesco Ferroni, Alexej Klushyn, Alexandros Paraschos, Justin Bayer, and Patrick van der Smagt. Fast approximate geodesics for deep generative models. In ICANN . 2019. URL: https://arxiv.org/abs/1812.08284 . ↩ Nutan Chen, Alexej Klushyn, Richard Kurle, Xueyan Jiang, Justin Bayer, and Patrick van der Smagt. Metrics for deep generative models. In AISTATS , 1540–1550. 2018. URL: https://arxiv.org/abs/1711.01204 . ↩ Nutan Chen, Alexej Klushyn, Alexandros Paraschos, Djalel Benbouzid, and Patrick van der Smagt. Active learning based on data uncertainty and model sensitivity. IEEE/RSJ IROS , 2018. URL: https://arxiv.org/abs/1808.02026 . ↩","tags":"blog","url":"https://argmax.ai/blog/geodesic/"},{"title":"[video] Erwin Coumans - 2019-06-28","text":"Title Sim-to-Real for Robot Reinforcement Learning Abstract Robotics at Google is a research team devoted to exploring how machine learning can revolutionize the world of robotics. We are interested if we can train policies in simulation and transfer them to real robots. This transfer involves dealing with the differences of idealized simulations and the complexities of the real world, also known as the simulation reality gap. We discuss our research and experiences in dealing with our sim-to-real research applied to robotic grasping and locomotion control of legged robots. In both cases, we need a deep understanding of dynamics and environment through sensing and learning and use this knowledge to build a simulation that is sufficiently rich to allow the transfer of policies. We also discuss various approaches to use machine learning to automatically deal with the reality gap.","tags":"talks","url":"https://argmax.ai/talks/coumans/"},{"title":"[video] Marc Deisenroth - 2019-05-13","text":"Title Data-Efficient Reinforcement Learning Abstract On our path toward fully autonomous systems, i.e., systems that operate in the real world without significant human intervention, reinforcement learning (RL) is a promising framework for learning to solve problems by trial and error. While RL has had many successes recently, a practical challenge we face is its data inefficiency: In real-world problems (e.g., robotics) it is not always possible to conduct millions of experiments, e.g., due to time or hardware constraints. In this talk, I will outline three approaches that explicitly address the data-efficiency challenge in reinforcement learning using probabilistic models. First, I will give a brief overview of a model-based RL algorithm that can learn from small datasets. Second, I will describe an idea based on model predictive control that allows us to learn even faster while taking care of state or control constraints, which is important for safe exploration. Finally, I will introduce an idea for meta learning (in the context of model-based RL), which is based on latent variables. Key references: Marc P. Deisenroth, Dieter Fox, Carl E. Rasmussen, Gaussian Processes for Data-Efficient Learning in Robotics and Control, IEEE Transactions on Pattern Analysis and Machine Intelligence, volume 37, pp. 408–423, 2015 Sanket Kamthe, Marc P. Deisenroth, Data-Efficient Reinforcement Learning with Probabilistic Model Predictive Control, Proceedings of the International the Conference on Artificial Intelligence and Statistics (AISTATS), 2018 Steindór Sæmundsson, Katja Hofmann, Marc P. Deisenroth, Meta Reinforcement Learning with Latent Variable Gaussian Processes, Proceedings of the International the Conference on Uncertainty in Artificial Intelligence (UAI), 2018","tags":"talks","url":"https://argmax.ai/talks/deisenroth/"},{"title":"[video] Martin Riedmiller - 2019-03-29","text":"Title Machines that learn from scratch Abstract Being able to autonomously learn ‘from scratch'—i.e. with a minimum amount of prior knowledge—is a key ability of intelligent systems. This credo is the driving motivation behind our research on reinforcement learning methods for the control of dynamical systems. While we have seen tremendous progress in the area of deep reinforcement learning in the last couple of years, its direct application to real systems still remains a challenge. Key requirements for agents mastering the real world are data-efficiency and reliability of learning, since data-collection in real environments, e.g. on real robots, is time intensive and often expensive. I will highlight two main areas of progress that we consider crucial for progress towards this goal—improved off-policy learning methods from large data sets and better exploration. I will give examples of simulated and real robots that, by following these principles, can learn increasingly complex tasks from scratch.","tags":"talks","url":"https://argmax.ai/talks/riedmiller/"},{"title":"Machine learning Video Lectures","text":"Between 2011 and 2017, researchers now at argmax.ai organised the main Machine Learning lecture at TUM Informatics. Using an inverted-classroom approach, all slides are commented as video lectures. We decided to make the videos and slides publicly available here. Lecture material","tags":"news","url":"https://argmax.ai/news/ML-course/"},{"title":"Lecture 01","text":"","tags":"ml course","url":"https://argmax.ai/ml-course/lecture-01-proba/"},{"title":"Lecture 02","text":"Additional Material Chapter 16.2 Classification and Regression Trees (CART) in Machine Learning: A Probabilistic Perspective , Kevin Murphy, or Chapter 14.4 Tree-based Models in Pattern Recognition and Machine Learning , Christopher Bishop, or Chapter 3 Classification and Regression Trees , Understanding Random Forests , in Gilles Louppe. http://www.r2d3.us/visual-intro-to-machine-learning-part-1/ does a good job at visually explaining decision trees.","tags":"ml course","url":"https://argmax.ai/ml-course/lecture-02-trees/"},{"title":"Lecture 03","text":"Additional Material Chapter 1.4.1 - 1.4.3 in Machine Learning: A Probabilistic Perspective , Kevin Murphy. Probabilistic k-NN: Chapter 14 Nearest Neighbour Classification in Bayesian Reasoning and Machine Learning , David Barber. Neighbourhood Components Analysis , J. Goldberger, S. Roweis, G. Hinton, R. Salakhutdinov Chris Colah gives a very nice introduction to information theory and can help you understand entropy.","tags":"ml course","url":"https://argmax.ai/ml-course/lecture-03-knn/"},{"title":"Lecture 04","text":"","tags":"ml course","url":"https://argmax.ai/ml-course/lecture-04-inference/"},{"title":"Lecture 05","text":"","tags":"ml course","url":"https://argmax.ai/ml-course/lecture-05-normal/"},{"title":"Lecture 06","text":"","tags":"ml course","url":"https://argmax.ai/ml-course/lecture-06-regression/"},{"title":"Lecture 07","text":"","tags":"ml course","url":"https://argmax.ai/ml-course/lecture-07-kernels/"},{"title":"Lecture 08","text":"","tags":"ml course","url":"https://argmax.ai/ml-course/lecture-08-classification/"},{"title":"Lecture 09","text":"","tags":"ml course","url":"https://argmax.ai/ml-course/lecture-09-networks/"},{"title":"Lecture 10","text":"Additional Material Gaussian Processes for Machine Learning by Rasmussen and Williams. Chapter 15 in Machine Learning: A Probabilistic Perspective Chapter 6.4 in Pattern Recognition and Machine Learning Chapter 19 in Bayesian Reasoning and Machine Learning","tags":"ml course","url":"https://argmax.ai/ml-course/lecture-10-gp/"},{"title":"Lecture 11","text":"Additional Material Chapter 12 in Machine Learning: A Probabilistic Perspective Chapter 12 in Pattern Recognition and Machine Learning","tags":"ml course","url":"https://argmax.ai/ml-course/lecture-11-unsupervised/"},{"title":"Lecture 12","text":"","tags":"ml course","url":"https://argmax.ai/ml-course/lecture-12-lvm/"},{"title":"Exam 1","text":"Exam Solution","tags":"ml course","url":"https://argmax.ai/ml-course/exam_1/"},{"title":"Exam 2","text":"Exam Solution","tags":"ml course","url":"https://argmax.ai/ml-course/exam_2/"},{"title":"Exam 3","text":"Exam Solution","tags":"ml course","url":"https://argmax.ai/ml-course/exam_3/"},{"title":"Sami Haddadin - 2018-10-18","text":"Title Machine Intelligence: bridging the gap between robotics and AI Abstract Important breakthroughs in robotics and artificial intelligence have enabled the first real-world applications of flexible, human-centered robot systems. Controlled by intelligent programming and interaction systems that \"understand\" man and machine, even laymen can use state-of-the-art robot technology for the first time. Their commercial introduction represents a step change in the way intelligent machines meet human needs beyond the industrial sector, e.g. also in the healthcare or private sector. In other words, they become everyday intelligent helpers in a wide variety of applications to make our lives easier. However, several grand challenges remain to be solved before unifying the fields of robotics and artificial intelligence to machine intelligence. First, the technological limits of sensory-motor and holistic system design need to be pushed significantly further in order to come closer to the unmatched performance and embodied intelligence of the human body. Second, we face the challenge of unifying the two previously separate paradigms of model-based control with data-driven machine learning algorithms such that next generation AI-algorithms seamlessly bridge the gap between physical and virtual world.","tags":"talks","url":"https://argmax.ai/talks/haddadin/"},{"title":"Network Architecture Optimisation","text":"Intuition and experience. Probably, that's the answer you would get if you happen to ask deep learning engineers how they chose the hyperparameters of a neural network. Depending on their familiarity with the problem, they might have done some good three to five full dataset runs until a satisfactory result popped up. Now, you might say, we surely could automate this, right, after all we do it implicitly in our heads? Well, yes, we definitely could, but should we? Imagine you want to search among a single hyperparameter, say the depth of the network. How about some \\(\\{3, 5, 8, 11\\}\\) -layer deep networks. This will require you at least four training cycles consisting in creation, initialisation, training until convergence and evaluation on a held-out test set. Maybe that's not that bad. What happens, however, if you decide to search for an optimal layer size too? In convolutional neural networks, you can even pick strides, filter sizes and so on. The search space quickly grows beyond any imaginable human patience. And let's admit it, most of the time you just pretend to be happy with what you end up with after a couple of trials. Nevertheless, the situation is far from hopeless as there's still a way to learn the architecture directly from the data! In the following blog post we will look into that and show an approach that allows us to probabilistically interpret the learnt architecture and thereby spot engineered design misspecifications. Moreover, we will do it the Bayesian way, meaning that we will incorporate our architectural views merely as prior beliefs rather than hard constraints. Bayesian deep learning Being Bayesian about anything as complex as a neural architecture is all but easy. In essence, we are asking for the form of a posterior distribution over some parameters \\(\\alpha\\) after observing labelled data \\((\\mathbf{x},\\, \\mathbf{y})\\) , or \\(p\\left(\\alpha\\mid\\mathbf{x},\\, \\mathbf{y}\\right)\\) for short. The Bayes' rule of probability tells us that: $$ p\\left(\\alpha \\mid \\mathbf{x},\\, \\mathbf{y} \\right) = \\frac{p\\left(\\mathbf{y}\\mid\\mathbf{x},\\, \\alpha\\right)p\\left(\\alpha\\right)}{p\\left(\\mathbf{y}\\mid\\mathbf{x}\\right)} $$ Due to the intractability of computing the evidence \\(p\\left(\\mathbf{y}\\mid\\mathbf{x}\\right)\\) we don't even dream of estimating \\(p\\left(\\alpha\\mid\\mathbf{x},\\, \\mathbf{y}\\right)\\) exactly. Instead we will reside to approximate inference techniques such as variational Bayes (VB) where we approximate \\(p\\left(\\alpha\\mid\\mathbf{x},\\, \\mathbf{y}\\right)\\) with a \\(\\theta\\) -parameterised distribution \\(q_\\theta\\left(\\alpha\\mid\\mathbf{x},\\, \\mathbf{y}\\right)\\) . Fortunately, Jordan et al. (1999) showed that the dissimilarity between \\(q_\\theta\\left(\\alpha\\mid\\mathbf{x},\\, \\mathbf{y}\\right)\\) and \\(p\\left(\\alpha\\mid\\mathbf{x},\\, \\mathbf{y}\\right)\\) can be decreased without explicitly computing \\(p\\left(\\mathbf{y}\\mid\\mathbf{x}\\right)\\) . The trick is to learn the \\(\\theta\\) such that a quantity called the E vidence L ower BO und is maximised: $$ \\mathcal{L}_{\\text{ELBO}}\\left(\\alpha,\\, \\mathbf{x},\\, \\mathbf{y}\\right) = \\mathbb{E}_{q_{\\theta}\\left(\\alpha\\mid\\mathbf{x},\\, \\mathbf{y}\\right)}[\\log{p\\left(\\mathbf{y}\\mid\\mathbf{x},\\, \\alpha\\right)}] - \\mathrm{KL}\\left(q_\\theta\\left(\\alpha\\mid\\mathbf{x},\\, \\mathbf{y}\\right)\\mid\\mid p\\left(\\alpha\\right)\\right) $$ However, this too is not computable in closed form and we will have to approximate it with sampling. We can go on and on discussing the issues and merits of this approach but we will stop here and instead go straight into the core of this post—applying VB to efficiently infer an approximate posterior distribution over the architectural parameters. Bayesian architecture learning We can think of certain structural hyperparameters as discrete random variables, e.g. the depth of a network and the size of a layer are well described by positive integer numbers. A categorical distribution may seem like a good modelling choice as it is flexible enough to represent every discrete distribution with domain \\(\\{1, 2, \\dots, K\\}\\) —only thing we have to do is to learn the probabilities \\(\\boldsymbol{\\pi} = (\\pi_1, \\pi_2, \\dots, \\pi_K)\\) for each category. Unfortunately, to do this we cannot use the backpropagation algorithm because a sample of the categorical distribution is a non-differentiable transformation of \\(\\boldsymbol{\\pi}\\) and some external noise \\(\\boldsymbol{\\epsilon}\\) : $$ c = {\\mathrm{arg}\\,\\mathrm{max}}_{i} \\log{\\pi}_i + \\epsilon_i $$ Instead we use a continuous approximation to it due to Maddison et al. (2016) and Jang et al. (2016) , where the non-differentiable \\({\\mathrm{arg}\\,\\mathrm{max}}\\) operator is replaced with the smooth \\(\\mathrm{softmax}\\) : $$ \\tilde{c}_i = \\frac{\\exp{\\left(\\frac{\\log{\\pi}_i + \\epsilon_i}{\\tau}\\right)}}{\\sum_j \\exp{\\left(\\frac{\\log{\\pi}_j + \\epsilon_j}{\\tau}\\right)}} $$ Notice that \\(\\mathbf{\\tilde{c}} = (\\tilde{c}_1, \\tilde{c}_2, \\dots, \\tilde{c}_K)\\) is not a one-hot vector anymore and that the temperature parameter \\(\\tau\\) controls the degree of discreteness. But, most importantly, we can express, say, the size of the layer as a sample of a distribution the parameters of which we can learn via backpropagation! In order to bridge the gap between this result and the \\(\\mathcal{L}_{\\text{ELBO}}\\) objective we discussed earlier, we only have to define a prior distribution over the architectural variable and express the data likelihood as a function of it without breaking the differentiability of the neural network. But that's just nothing compared to the mental and computational effort needed to find an optimal architecture using a search-based procedure. So let's do it quickly. Adaptive layer size Let \\(\\alpha\\) be the random variable representing the number of units within a layer. We can define prior and approximate posterior distributions respectively as: \\begin{align*} p_{\\boldsymbol{\\pi}_\\text{prior}, \\tau_\\text{prior}}(\\alpha) &= \\mathrm{ConcreteCategorical}(\\alpha\\mid\\boldsymbol{\\pi}_\\text{prior}, \\tau_\\text{prior}) \\\\ q_{\\boldsymbol{\\pi}, \\tau}(\\alpha\\mid\\mathbf{x}, \\mathbf{y}) &= \\mathrm{ConcreteCategorical}(\\alpha\\mid\\boldsymbol{\\pi}, \\tau) \\end{align*} where we fix \\(\\tau\\) and learn only \\(\\boldsymbol{\\pi}\\) to facilitate our task. If we want to learn the layer size for example, we must express the output of a layer as a deterministic operation of the sample \\(\\hat{\\alpha} \\sim q_{\\boldsymbol{\\pi}, \\tau}(\\alpha\\mid\\mathbf{x}, \\mathbf{y})\\) and the weights and biases of it. One way to do it is to deterministically compute a quasi-binary mask \\(M(\\hat{\\alpha})\\) that (approximately) lets \\({\\mathrm{arg}\\,\\mathrm{max}}_i \\hat{\\alpha}_i\\) unit activations through and shadows the rest, e.g. we can build it as a linear combination with coefficients \\(\\hat{\\alpha}\\) of some cleverly-chosen set of binary masks: $$ M(\\hat{\\alpha}) = \\mathbf{U}\\hat{\\alpha}, \\quad \\mathbf{U} := \\begin{bmatrix} 1 & 1 & 1 & \\dots & 1 \\\\ 0 & 1 & 1 & \\dots & 1 \\\\ 0 & 0 & 1 & \\dots & 1 \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & 0 & \\dots & 1 \\\\ \\end{bmatrix} $$ Below you can see a concrete sample in the left and the corresponding mask in the right. The sharpness of this mask is mainly determined by \\(\\tau\\) but keep in mind that the gradients are inversely proportional to \\(\\tau\\) and learning becomes instable for \\(\\tau \\rightarrow 0\\) . Job done, let's see what we can learn with it... well, wait a second. Before we move on, we remark that the variational parameters \\(\\boldsymbol{\\pi}\\) are so unconstrained that it might be hard to interpret the posterior distribution. What would be the desired size in a multi-modal scenario? How do we read out the uncertainty over the layer size? After all, at the end of the day we would like to be able to tailor the architecture according to the learnt posterior distribution and fix it for good. To do this, we will have to constrain \\(\\boldsymbol{\\pi}\\) in a way that ensures unimodality and an easily interpretable variance. We reside to the (modified) chicken soup of the distributions—the truncated Normal distribution . That is, instead of \\(\\boldsymbol{\\pi}\\) we now learn \\(\\mu\\) and \\(\\sigma\\) and set: $$ \\pi_i = \\frac{\\mathcal{N}_{\\text{trunc}}(i \\mid \\mu, \\sigma, 1, K)}{\\sum_j \\mathcal{N}_{\\text{trunc}}(j \\mid \\mu, \\sigma, 1, K)} $$ We can simply read out \\(\\mu\\) to get the most likely estimate for the size of the layer and \\(\\sigma\\) (which is not a standard deviation any more!) can be interpreted as an uncertainty around that point. Adaptive network depth To model the total depth of a network we can't just broadcast the mask over the outputs of each layer, as even a single fully masked intermediate layer will kill the output of the network. We go about this by using trainable skip connections which allow to bypass redundant layers. We can implement them by representing the layer as a convex combination of its input \\(\\mathbf{x}\\) and output \\(f(\\mathbf{W}\\mathbf{x} + \\mathbf{b})\\) controlled by a stochastic mixing coefficient \\(\\gamma \\sim \\mathrm{ConcreteBernoulli(\\pi)}\\) : $$ \\mathbf{\\hat{y}} = (1 - \\gamma)f(\\mathbf{W}\\mathbf{x} + \\mathbf{b}) + \\gamma\\mathbf{x} $$ In other words, we let \\(\\pi\\) represent the probability of skipping a layer and we learn it via backpropagation pretty much the same way we did for the adaptive layer size. Naturally, we can also define a concrete Bernoulli prior \\(p_{\\pi_\\text{prior}}(\\gamma)\\) . Without further ado, let's look into an example! Case-study: regression There is hardly any more trivial and yet intuitive way to see how neural networks work, than fitting a nicely plottable one-dimensional noisy data. In order to show the effectiveness of the methods we will consider two cases. First, we will show the adaptive layer size applied on a single layer neural network with 50 units and then we will go deep with a rather \"narrow\" 10-layer network. Finding the optimal layer size For the sake of insightfulness we will put a rather silly architectural prior distribution with \\(\\mu_\\text{prior}=1\\) and \\(\\sigma_\\text{prior}=2\\) and hope that the network will learn a minimalistic layer architecture that also explains the data well. In the leftmost figure you can see the training data and the current best fit, computed by sampling from \\(q_{\\boldsymbol{\\pi}, \\tau}(\\alpha\\mid\\mathbf{x}, \\mathbf{y})\\) . The middle plot shows the truncated normal distribution from which \\(\\boldsymbol{\\pi}\\) is derived and the rightmost image is an alternative visualisation showing the full history from the initialisation to the final solution. Indeed, the posterior over the size, as shown in the middle, shifts towards something more reasonable and thus unlocks more and more of the layer's capacity. It is only a matter of time for \\(\\mu\\) to settle and \\(\\sigma\\) to shrink at the nearly optimal unit count. Also, notice how the uncertainty is larger in the beginning when the layer size is inadequate and gradually sharpens later on, which gives us a good insight into how well the network structure is suited for the problem even without looking at the predictions! Finding the optimal network depth Ok, so far so good. We have shown that we can fit the data with one hidden layer hosting at least 21 units. To see whether we can also learn the depth of a deeper network, we will initialise 10 hidden layers of 5 units each, with a \\(\\pi_\\text{prior} = 0.99\\) (i.e. we skip a layer with 99% probability). Obviously the task cannot be reliably solved by a single layer, so the network will have to learn to overcome the rather strong prior. The animation below shows the fit on the left and the probabilities \\(\\pi\\) for each layer, colour-coded in shades of grey where black means definitively \"skip\" and white \"let through\" respectively. It is interesting to see how the network quickly learns to use the heavily muted layers, while gradually unlocking more and more of them. Apparently 5 layers of 5 units are enough to explain the data and the posterior over the skip variable \\(q_\\pi(\\gamma)\\) remains pretty close to the prior for the remaining 5 layers. If we wish, we could also combine the adaptive layer size and network depth approaches in a single elastic network and learn all hyperparameters jointly. For now, we leave this as an exercise for you! Final words In this blog post we have seen that it is very much possible to learn the basic architecture of feed-forward densely connected neural networks while in the same time tuning their weights to explain the data. This comes handy when you have no clue how to configure your model and also don't have the time and computational power to explore large hyperparameter spaces over many runs. Keep in mind that we have shown a method to infer an optimal layer size for standard layer types but there is no conceptual difficulty in extending it to convolutional and recurrent layers, where the mask is applied over the channels and the time steps axis respectively. Finally, we remark that despite its convenience, this technique adds an additional layer of complexity to the model. It is therefore best to use it only as a tool to infer near-optimal architectures. Once found, please do initialise a rigid model accordingly and train it until convergence. Good luck! This work was published at the International Conference on Artificial Intelligence and Statistics (AISTATS) 2019 if (!document.getElementById('mathjaxscript_pelican_#%&#64;#$&#64;#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%&#64;#$&#64;#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); } Bibliography Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization with gumbel-softmax. arXiv preprint arXiv:1611.01144 , 2016. ↩ Michael I Jordan, Zoubin Ghahramani, Tommi S Jaakkola, and Lawrence K Saul. An introduction to variational methods for graphical models. Machine learning , 37(2):183–233, 1999. ↩ Chris J Maddison, Andriy Mnih, and Yee Whye Teh. The concrete distribution: a continuous relaxation of discrete random variables. arXiv preprint arXiv:1611.00712 , 2016. ↩","tags":"blog","url":"https://argmax.ai/blog/archopt/"},{"title":"Deep Learning and Robotics Challenge 2018","text":"Volkswagen Group ML Research Lab invites students to join the 2018 Deep Learning and Robotics Challenge. In this challenge, which will take place from September 10 to October 19, 2018, you will collaborate with your peers in small teams to deploy machine learning within a robotics context. We expect your methods to rely on deep neural networks, developed on Tensorflow in Python. Note that your major input will be related to machine learning, and less so to robotics. All code that you will develop within this challenge will be made public. You, as anyone else, will have the rights to subsequently deploy it. We will also ask you to blog about your research work in our special blog. As part of the challenge, each team will be provided with two Panda 7-DoF robotic arms from Franka Emika. Additionally, we will give you access to ample GPU-based computing power. Your application should contain: your idea: Imagine you have access to a 7-DoF robotic arm. Invent a task and tell us how you would apply machine learning (max. 1 page); CV (max. 2 pages). So, within max. 3 pages, try to convince us to accept you. We only accept PDF submissions within the length limit. By the way, we can only accept students before their MSc degree who are enrolled at a university during their entire stay in our lab. One more thing. Even though Munich is not expensive on a global scale, accommodation is not cheap nor easy to get by—especially during Oktoberfest. To assist, during your stay at Volkswagen Data:Lab you will receive an income which you can use to cover your living expenses. Deadline for applications is July 31, 2018. Please note that the application site is in German only. If this blocks your application, please contact us at dlrc2018 [[at]] argmax [[dot]] ai for further assistance. Apply!","tags":"news","url":"https://argmax.ai/news/dlrc2018/"},{"title":"[video] Justin Bayer - 2018-07-26, 17:00","text":"Title Approximate Bayesian inference in spatial environments Abstract While purely data-driven methods have been an outstanding success story in the recent years, the injection of prior knowledge into our models is a viable mean to reduce the hunger for data of our algorithms. In this talk, we will do so by augmenting stochastic deep and recurrent models with an explicit map to tackle the problem of learning the spatial surroundings of an agent. Using variational Bayes and neural networks as our basic machinery, the resulting model let's us solve certain inference problems such as simultaneous localisation and mapping, autonomous exploration or control in a single model.","tags":"talks","url":"https://argmax.ai/talks/_bayer/"},{"title":"[video] Daniel Cremers - 2018-07-26, 16:00","text":"Title Direct Methods for 3D Reconstruction & Visual SLAM Abstract The reconstruction of the 3D world from images is among the central challenges in computer vision. Starting in the 2000s, researchers have pioneered algorithms which can reconstruct camera motion and sparse feature-points in real-time. In my talk, I will introduce direct methods for camera tracking and 3D reconstruction which do not require feature point estimation, which exploit all available input data and which recover dense or semi-dense geometry rather than sparse point clouds.","tags":"talks","url":"https://argmax.ai/talks/cremers/"},{"title":"Meet us at Automatica!","text":"Meet us at the booth B4.302! We will be present at Automatica demonstrating some of our latest works.","tags":"news","url":"https://argmax.ai/news/automatica2018/"},{"title":"[video] Sepp Hochreiter - 2018-05-04","text":"Title Deep Learning in Linz ( Sepp Hochreiter , Johannes Kepler University Linz) Abstract Deep Learning has emerged as one of the most successful fields of machine learning and artificial intelligence with overwhelming success in industrial speech, language and vision benchmarks. Consequently it evolved into the central field of research for IT giants like Google, facebook, Microsoft, Baidu, and Amazon. Deep Learning is founded on novel neural network techniques, the recent availability of very fast computers, and massive data sets. The main obstacle to learning deep neural networks is the vanishing gradient problem, which impedes credit assignment to the first layers of a deep network or to early elements of a sequence. Most major advances in Deep Learning can be related to avoiding the vanishing gradient. These advances include unsupervised stacking, ReLUs, residual networks, highway networks, and LSTM networks. Our current research is on self-normalizing neural networks (SNNs) which automatically avoid the vanishing gradient. SNNs are proved to converge to neuron activations having mean zero and variance one across samples using the Banach fixed-point theorem even under the presence of noise and perturbations. Generative adversarial networks (GANs) excel in generating images with complex generative models for which maximum likelihood is infeasible. We proved using the theory of stochastic approximations that a two time-scale update rule for training GANs converge under mild assumptions to a local Nash equilibrium. Using an analog to electric fields we derived Coulomb GANs for which it can be shown that there exists only one local Nash equilibrium that is the global one. With Coulomb GANs the learning problem is formulated as a potential field, where generated samples are attracted to training set samples but repel each other. Recently we focused on reinforcement learning and improved the credit assignment for delayed rewards. For delayed reward, Monte Carlo (MC) has high variance while temporal difference (TD) like Q-learning or SARSA has a very slow correction of its bias. We show that our LSTM-based approach to credit assignment learns exponentially faster than MC and TD for delayed rewards.","tags":"talks","url":"https://argmax.ai/talks/hochreiter/"},{"title":"Deep Variational Bayes Filter","text":"Machine-learning algorithms thrive in environments where data is abundant. In the land of scarce data, blessed are those who have simulators. The recent successes in Go or Atari games would be much harder to achieve without the ability to parallelise millions of perfect game simulations. But in many other domains, we cannot use this approach. For instance robotics, where simulations often fall short. After all, only phenomena that are understood well enough can be simulated. Everything else is necessarily idealised and abstracted. If we had accurate simulators for such domains, we could devise much more efficient learning algorithms around them. Just like we don't need to play millions of real-world games to make a machine learn Go, we wouldn't need to run dozens of robots for countless hours to acquire sufficient data. The key to simulators in these domains is accurate prediction. As Niels Bohr pointedly put it: \"Prediction is very difficult, especially if it's about the future.\" Luckily, machine learning is not alone in its quest for better predictions. Better predictions are the driving factor behind many scientific disciplines: any scientific hypothesis must allow falsifiable predictions. In this post, we will be looking into the approaches developed in other fields. We will draw inspirations from established methods, and introduce our own algorithm Deep Variational Bayes Filters (DVBF, Karl et al. (2017) ). DVBF solves shortcomings of many established method with the help of machine learning. Differential equations Let's start in Niels Bohr's own domain, physics. For 350 years, physicists have been using an elegant way for describing processes—differential equations. At its core, a differential equation is a predictor: how will a process evolve over time? And does that prediction comply with the observations we make in the real world? Why are differential equations such a successful tool? Let us look at a simple example, a one-link robot, also known as damped pendulum. We try to predict the displacement angle \\(\\theta\\) over time. This process is governed by the differential equation $$\\ddot\\theta = -\\frac bm\\dot\\theta - \\frac gL \\sin\\theta.$$ This simple example highlights the core features of differential equations at work. The differential equation is compact and local : we prefer to know the changes that will happen in a short horizon instead of the brittle global evolution. Instead of specifying a complicated, often brittle function \\(\\theta(t, \\theta_0)\\) for the angle at any point in time \\(t\\) from any initial displacement \\(\\theta_0\\) , it describes how the angle acceleration \\(\\ddot\\theta\\) is affected by the current state of the system, its displacement angle \\(\\theta\\) and the angle velocity \\(\\dot\\theta\\) . Because we locally look at the pendulum, we achieve a modular description: the differential equation consists of two separate terms—damping from friction, \\(\\frac bm\\dot\\theta\\) , and acceleration from gravity, \\(\\frac gL \\sin\\theta\\) . In a global description, we would need to consider their complex interplay. The local description makes things simpler, and it allows us to add or leave away assumptions. State-space systems Now we know the differential equation governing the pendulum. It depends on angle and angle velocity, and given these we can predict the evolution of the process. Great! What's left? Well, we need to obtain angle and angle velocity starting configuration for our prediction. The easy way out is to mount appropriate sensors and to keep our fingers crossed someone calibrated them properly. But more often than not, this is not an option. Plus it's boring! A camera, instead, is relatively cheap and easy to install. On the right is a (synthetic) video sequence of a simulated pendulum. In fact, for a human it's easy to predict how this video sequence will continue, because we have understood the underlying physical process. But how do we access the information about the state of the pendulum that is hidden in the pixels? Let us rephrase the question: how does the video frame at time \\(t\\) differ from angle and angle velocity at that point in time? What makes it easier to describe the dynamical process in terms of angles and angle velocities rather than pixels? Answering this question lead to the concept of state-space systems . In these systems, we make a distinction between the latent state \\(\\mathbf z_t\\) of a system, like angle and velocity, and observations \\(\\mathbf x_t\\) of it, like video frames. A state-space system consists of two components: Dynamics on the state, like a differential equation (or, because we siletnly switched to the more computer-friendly discrete systems, a difference equation ). It is a low-dimensional, often minimal description of the process. We will generally refer to this as the (latent) state transition. A rendering or measurement process that yields observations based on the latent state. This can mean that the latent state is only partially observable. We will refer to this process as the emission model. The core idea is that the true state is not observed, hence latent state. We can only infer it from the observations: what is the state, given the observations we have made? This sounds a lot like posterior inference! Let's look at state-space systems from a statistical perspective. Filtering The simple latent process then becomes a distribution over a sequence of latent states, \\(p(\\mathbf z_{1:T})\\) . Likewise, the emission process is a distribution over the observations given the latent states, \\(p(\\mathbf x_{1:T}\\mid\\mathbf z_{1:T})\\) . Our question—what is the state, given the observations we have made?—can now be answered in a rigorous framework. The answer is the posterior distribution \\(p(\\mathbf z_{1:T}\\mid\\mathbf x_{1:T})\\) , and by Bayes' theorem \\(p(\\mathbf z_{1:T}\\mid\\mathbf x_{1:T}) \\propto p(\\mathbf x_{1:T}\\mid\\mathbf z_{1:T})p(\\mathbf z_{1:T})\\) . In our scenarios, this posterior distribution is also called filter distribution : it filters the quintessential information, the latent state, from the observations. The resulting algorithms are called Bayes filters . Arguably the most famous implementation of such a Bayes filter is the Kalman filter . Airplane autopilots depend on its tracking abilities, as does your GPS navigation system, and many, many more. Where is the limit? Done!? Not quite yet. The Kalman filter succeeds by putting strong assumptions on the state-space system, in that both the difference equation and the measurement process need to be linear Gaussian models. The Kalman filter is provably optimal in that setting . These assumptions are (approximately) valid in many interesting scenarios. The Kalman filter is the go-to algorithm for tracking because large-scale natural motions are approximately linear and Gaussian. After all, it's safe to board an airplane with a Kalman filter position tracking. Yet, highly nonlinear observations, like camera frames, cannot be filtered by Kalman filters. In general cases, the Bayes filter is intractable. And there is an even bigger caveat: in all the stages so far, we assumed that we know the underlying process, the difference equation, and through Bayes' formula the filter depends on it. But coming up with suitable state space representations is laborious, costly, and requires a significant amount of domain knowledge. Deep Variational Bayes Filters Luckily, over the past years machine learning has taken a deep dive into unsupervised representation learning. The most useful tool for our purposes is inference via amortised variational Bayes. It was popularised by variational auto-encoders (VAE, Kingma and Welling (2014) ). A VAE learns a model \\(p(\\mathbf x \\mid \\mathbf z)\\) with a fixed prior \\(p(\\mathbf z)\\) , and simultaneously an approximate posterior \\(q(\\mathbf z \\mid \\mathbf x)\\) . The conditional random variables are implemented with neural networks. If we extend this idea to sequential data, we can tackle both caveats: we can learn an approximate Bayes filter even for nonlinear data; simultaneously, we learn the state transition in latent space plus the emission model. Both leverage the modelling powers of neural networks to overcome the shortcomings of methods like the Kalman filter. This is the core idea behind Deep Variational Bayes Filters (DVBF): We overcome the limitations of well-understood Bayes filters, and we do so by surgically replacing limiting components with neural networks. Instead of entirely replacing a well-established approach, we extend it to previously intractable data with findings from deep learning. This gives us the best of both worlds. And here is how DVBF looks in action on the pendulum example: The approximate filter distribution, implemented by a neural net, maps the sequence of frames into a three-dimensional latent space. The model has learnt that a two-dimensional barrel-shaped manifold is a good state-space representation. Intriguingly, when we compare the latent state to the ground truth, we find a strong relation. Without a notion of pendulum physics or even angles, the learning algorithm autonomously encodes the real-world angle on a circle, and the ground-truth angle velocity is encoded perpendicular to that. The smooth colouring using ground-truth angle data highlights that. At this point, our journey in this article has gone full circle: we started off by looking at the differential equation of the pendulum, and after a series of further considerations, we have found an unsupervised algorithm that learns transitions akin to this very differential equation from raw data. And just like differential equations, this approach is compact, local, and modular. Especially the modularity can be used to our advantage. Instead of using a less interpretable neural network, we may use other components that make use of some system knowledge. We can compose the latent state process from simple principles, rather than ever more complex models in the observation space. We've also trained a probabilistic model of our system. A simulator! We can sample the behaviour of the system without interacting with it in the real world. What's next? Arguably, we dealt with not more than an illustrative example in this post. Yet applications of DVBF all but stop here. Having an explicit model for sequence data is very valuable, and we will close this post by looking at two advanced applications. The first successful application of DVBF is Empowerment Karl et al. (2017) . Loosely speaking, empowerment is a measure of how diversely and effectively an agent can influence its environment. As such, it is a natural candidate for intrinsic motivation in control an reinforcement learning. We have shown that Empowerment can lead to meaningful behaviour in very different agents and environments in the absence of any other cost function. At the core of our Empowerment algorithm is DVBF. An agent needs to be aware of the consequences of its actions to be able to estimate its current Empowerment. If the agent can query a simulation rather than interacting with the environment, this stabilises the empowerment estimates. Another important application is a new view on sensors. Sensors are expensive because it is difficult to manufacture them with good calibration properties. In our lab, we have applied this principle to artificial skin. Rather than the costly state-of-the-art sensors, we can produce durable tactile sensors at a fraction of the cost, and reach sensor accuracy by post-processing the low-quality data with DVBF. We will take a closer look at these two cases in later posts on this blog. An open-source version of DVBF will be available soon; it will be announced here. arXiv if (!document.getElementById('mathjaxscript_pelican_#%&#64;#$&#64;#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%&#64;#$&#64;#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); } Bibliography Maximilian Karl, Maximilian Soelch, Justin Bayer, and Patrick van der Smagt . Deep variational bayes filters: unsupervised learning of state space models from raw data. In Proceedings of the International Conference on Learning Representations (ICLR) . 2017. URL: http://arxiv.org/abs/1605.06432 . ↩ Maximilian Karl, Maximilian Soelch, Philip Becker-Ehmck, Djalel Benbouzid, Patrick van der Smagt, and Justin Bayer. Unsupervised real-time control through variational empowerment. arXiv :1710.05101 [stat] , 2017. URL: http://arxiv.org/abs/1710.05101 , arXiv:1710.05101 . ↩ Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In Proceedings of the 2nd International Conference on Learning Representations (ICLR) . 2014. ↩","tags":"blog","url":"https://argmax.ai/blog/dvbfintro/"},{"title":"About","text":"Established in 2016, Volkswagen Group Machine Learning Research Lab, located in Munich, was set up as a fundamental research lab on topics close to what we think artificial intelligence is about: machine learning and probabilistic inference, efficient exploration, and optimal control. Our research topics are championed by lab members. We form agile groups on the spur to pursue new topics and solidify promising avenues of research. It's really a no-brainer why a large company is interested in these methodologies. But why fundamental research? There is a plethora of reasons, but one key message is: artificial intelligence, in its early 21st century interpretation, is only just beginning. While there are already many successful small applications of the related methodologies—in particular, applications based on supervised learning—we all realise that computer \"intelligence\" is still far ahead. The complexity of the topics involved makes us realise that a single lab can hardly bring the trophy home by itself. Therefore we actively pursue an open-source approach, giving you access to all scientific and implementational issues of our work. This blog is our instrument to inform you about our research, and give background information around scientific papers, open-sourced software, and demonstrations.","tags":"blog","url":"https://argmax.ai/blog/about/"},{"title":"Adnan Akhundov","text":"After 15 years in software engineering, Adnan decided to dive into the field of machine learning and artificial intelligence. Leveraging his experience in designing and developing software systems at different scales, Adnan is supporting the fundamental research conducted in the Lab by creating and maintaining components of the research infrastructure, as well as directly participating in the research process. Interests machine learning engineering probabilistic programming software engineering distributed systems","tags":"team","url":"https://argmax.ai/team/adnan-akhundov/"},{"title":"Alexandros Paraschos","text":"Alexandros Paraschos joined Volkswagen Group ML Research Lab as a Research scientist and works in the areas of robotics and machine learning. He obtained his PhD from Technical University of Darmstadt, under the supervision of Gerhard Neumann and Jan Peters. During his PhD, he focused on Robot Learning for Complex Motor Skills. Previously, Alexandros has been a research associate in Cognitive Robotics Research Centre (CRRC), at University of Wales, working with Torbjoern Dahl. Earlier, Alexandros studied Electronic and Computer Engineering at Technical University of Crete and received his diploma under the supervision of Michail Lagoudakis. During his studies at Technical University of Crete, Alexandros participated at the Kouretes robocup team. Google Scholar DBLP","tags":"team","url":"https://argmax.ai/team/alexandros-paraschos/"},{"title":"Alexej Klushyn","text":"Alexej joined the Volkswagen Group ML Research Lab in March 2017, where he is pursuing a PhD focusing on variational inference in latent-variable models. He holds a master's degree in physics from the Ludwig Maximilian University of Munich. Interests probabilistic graphical models probabilistic sequence models representation learning metric learning variational inference","tags":"team","url":"https://argmax.ai/team/alexej-klushyn/"},{"title":"Andrea Skolik","text":"Andrea completed her master's degree in computer science at Ulm University in 2015, where she focussed on machine learning, computer vision and robotics. After that she spent two years working as a software developer and built software for automated training of machine learning models, among other things. At the beginning of 2018, she joined the Data:Lab to pursue a PhD in quantum machine learning, where she now works on teaching quantum computers how to learn. Interests quantum computing (quantum) neural networks optimisation unsupervised learning","tags":"team","url":"https://argmax.ai/team/andrea-skolik/"},{"title":"Ankur Goel","text":"Ankur completed his Bachelor of Technology in Production and Industrial Engineering from Indian Institute of Technology, Delhi. He worked at the Data:Lab from May to December 2017 as an intern on the development of tactile sensors. He is currently a research fellow at Harvard Biodesign Lab and is working on the Soft Robotics Toolkit project. Interests Soft Robotics Medical Devices Educational Technology","tags":"team","url":"https://argmax.ai/team/ankur-goel/"},{"title":"Atanas Mirchev","text":"Atanas joined argmax.ai in May 2017. In 2018 he obtained his MSc in Computer Science from the Technical University of Munich. His Master's thesis dealt with the probabilistic modelling and exploration of spatial environments. He is now pursuing a PhD in the research lab, seeking principled ways to imparting structure to Bayesian models and incentivising explorative behaviour with the help of information theory. Interests approximate inference in probabilistic models intrinsic motivation exploration and modelling of spatial environments decision making under uncertainty implicit variational families","tags":"team","url":"https://argmax.ai/team/atanas-mirchev/"},{"title":"Baris Kayalibay","text":"Baris obtained his MSc in Computer Science at the Technical University of Munich. He has been a part of the ML Research Lab since 2017. In late 2019, he started his PhD studies working on Bayesian modelling of spatial environments. Interests Bayesian reasoning in spatial environments decision making under uncertainty variational inference","tags":"team","url":"https://argmax.ai/team/baris-kayalibay/"},{"title":"Botond Cseke","text":"Botond has completed a PhD in Machine Learning at Radboud University Nijmegen under the supervision of Prof. Tom Heskes where he learnt not care about anything that cannot be described by a probabilistic graphical model. This was followed by two post-docs at the University of Edinburgh (bio-informatics) and Microsoft Research Cambridge (approximate inference), respectively. He joined the Volkswagen Group ML Research Lab in October 2017 where he enjoys modelling with probabilities and experimenting with inference in probabilistic graphical models using neural networks or deep neural models, whatever you fancy to call it. In his free time he does another type of modelling https://www.instagram.com/csekebotond09/?hl=en Interests variational inference in graphical models variational inference in time series models generative adversarial networks","tags":"team","url":"https://argmax.ai/team/botond-cseke/"},{"title":"Djalel Benbouzid","text":"Djalel obtained his PhD in Machine Learning from the University Paris-Saclay, under the supervision of Balázs Kégl. During his PhD, in immersion within a particle physics laboratory, he explored Reinforcement Learning methods for budgeted learning and fast supervised prediction, typically to be applied in high-energy physics and trigger design. Djalel has various AI-related interests, such as hyperparameter optimisation, collaborative machine learning, and medical applications; however, his main interest remains data-efficient reinforcement learning. Interests reinforcement learning model-based reinforcement learning meta-learning","tags":"team","url":"https://argmax.ai/team/djalel-benbouzid/"},{"title":"Eileen Zhang","text":"","tags":"team","url":"https://argmax.ai/team/eileen-zhang/"},{"title":"Eva Schinzel","text":"","tags":"team","url":"https://argmax.ai/team/eva-schinzel/"},{"title":"Felix Frank","text":"Felix has completed a master's degree in automation and control at the RWTH Aachen University. He has worked as a research student in the field of optimal control for vehicle combustion engines. Felix joined the Volkswagen Group ML Research Lab in September 2017 to write his master's thesis. During his thesis he developed a software framework aimed at integrating high-level machine learning methods and low-level robotics controls. He is currently pursuing a PhD degree on topics related to stochastic optimal control in robotics. Interests optimal control theory reinforcement learning robotics variable-stiffness actuation","tags":"team","url":"https://argmax.ai/team/felix-frank/"},{"title":"Georgi Dikov","text":"","tags":"team","url":"https://argmax.ai/team/georgi-dikov/"},{"title":"Grady Jensen","text":"After spending several years working in industry, the last few years using my machine learning knowledge in the realm of healthcare and insurance on several IBM Watson Healthcare projects, I discovered a deep interest in research. I am entralled by the obscure nature of the nervous system. Although many areas of this system are well understood, there are many other areas, such as memory or cognition, that are elusive and puzzling. I am interested in research that bridges the gap between AI and neuroscience; finding ways to leverage the ability of current AI algorithms and methodologies to understand the avalanche of neuroscience data while concomitantly using inspiration from neuroscience to create artificial models that resemble the biological. Interests leveraging machine learning and computer vision in neuroscience biologically plausible AI data with multiple modalities","tags":"team","url":"https://argmax.ai/team/grady-jensen/"},{"title":"Jiaojiao Ye","text":"Jiaojiao is currently pursuring her master's degree at the Technical University of Munich, focusing on Robotics and Machine Learning. Earlier, she obtained a bachelor degree majoring in control theory from Zhejiang University. She joined the Machine Learning Research Lab at Volkswagen Group for her master thesis in June 2019, working on conditional Variational Autoencoders and Probabilistic Movement Primitives for Human-Robot interaction. Interests generative model reinforcement learning motion planning for robotics computer vision","tags":"team","url":"https://argmax.ai/team/jiaojiao-ye/"},{"title":"Jorrit van der Laan","text":"Jorrit did his bachelor's in mathematics at the Radboud University, but decided to pursue a master's in computer science due to an increasing interest in machine learning. He joined the ML Research Lab at Volkswagen Group in February 2019, working on sequential modeling in partially observed environments. Interests probabilistic sequential modelling variational inference","tags":"team","url":"https://argmax.ai/team/jorrit-van-der-laan/"},{"title":"Justin Bayer","text":"Justin joined argmax.ai in October 2016. He obtained a Phd from Technical University of Munich in 2015, where he had been working under the supervision of Patrick van der Smagt since 2010. Before that he obtained his Diploma in computer science from TUM under the supervision of Jürgen Schmidhuber at IDSIA. Interests Bayesian deep learning approximate inference in stochastic systems decision making under uncertainty intrinsic motivation such as artificial curiosity or empowerment Bayesian reasoning in spatial environments","tags":"team","url":"https://argmax.ai/team/justin-bayer/"},{"title":"Karolina Stosio","text":"Karolina graduated from the International Master Programme in Computational Neuroscience jointly held by Technische Univertitat Berlin and Humbold Universitat zu Berlin. She conducted her master thesis research under the supervision of Matthias Bethge in the Centre for Integrative Neuroscience in Tuebingen. Karolina enjoys asking herself 'could a brain compute this way?' when confronted with new ML algorithms and concepts. Recently she has gotten interested in robotics just to be on the right side in case the robots take over. Interests computational neuroscience variational inference local learning rules","tags":"team","url":"https://argmax.ai/team/karolina-stosio/"},{"title":"Liesbeth Claessens","text":"Liesbeth joined Volkswagen AI Research after her nascent interest in machine learning was further kindled by a presentation about empowerment, an information theoretic quantity that expresses the perceptible influence an agent has on his environment. She wanted to learn everything about it, and that is exactly what her bachelor thesis at the lab allows her to do. Her topic consists of giving an overview of modern ways of approximating empowerment, as computing it with classical methods is unfortunately intractable in most settings. Interests intrinsically motivated reinforcement learning policy gradient methods reproducibility standards for deep reinforcement learning research","tags":"team","url":"https://argmax.ai/team/liesbeth-claessens/"},{"title":"Maximilian Karl","text":"Maximilian Karl started his PhD at the Technical University of Munich in 2014. In 2017 he joined the Volkswagen Group ML Research Lab as a research scientist. He holds a Masters degree in Robotics, Cognition, Intelligence from the Technical University of Munich. His work focusses on unsupervised learning and efficient variational inference methods for time series modelling. He is also interested in the application of information theory to stochastic control and unsupervised control. Interests intrinsic motivation unsupervised learning of state space models approximate inference for stochastic optimal control embedded systems and robotics","tags":"team","url":"https://argmax.ai/team/maximilian-karl/"},{"title":"Maximilian Soelch","text":"Max obtained his MSc in mathematics from Technical University of Munich (TUM) and Royal Institute of Technology Stockholm (KTH) in 2016. His thesis dealt with anomaly detection in robot sequence data. During his PhD, this developed into a quest for ever better neural sequence models for understanding dynamical systems. He is also interested in applying these models, which led him into examining the representation and processing of beliefs over system states. Interests probabilistic sequence models system identification belief representation a Bayesian approach to all elements of a dynamical system variational inference","tags":"team","url":"https://argmax.ai/team/maximilian-soelch/"},{"title":"Michael Streif","text":"Michael received his Master's degree in physics at the University of Freiburg, Germany, in 2016. During his master thesis, he worked in the 'Quantum System Engineering' group in Oxford and focused on quantum probing of complex systems. End of 2017, Michael joined the Data:Lab as a PhD student in the field of quantum computing. Interests quantum computing quantum many-body systems quantum machine learning","tags":"team","url":"https://argmax.ai/team/michael-streif/"},{"title":"Michelle Plötner","text":"Working as a sales consultant in the automotive area for more than 5 years awakened Michelle's interest in enhancing the customer orientation within companies. The deployment of AI to increase human efficiency is a great motivator for her, and made her decide to work with experts in machine learning at Volkswagen Group ML Research Lab.","tags":"team","url":"https://argmax.ai/team/michelle-plotner/"},{"title":"Neha Das","text":"Neha is currently pursuing a Master's degree in Informatics at Technical University of Munich. She has been a part of the AI research at Volkswagen Data Lab since June 2018, working on learning state-space models of camera-based drones for intrinsically motivated control. Interests intrinsically motivated control sequence modelling variational inference deep learning for images","tags":"team","url":"https://argmax.ai/team/neha-das/"},{"title":"Nutan Chen","text":"Nutan received a PhD in Informatics from Technische Universität München under the supervision of Patrick van der Smagt. He received his master degree from National University of Singapore under the supervision of Chee-Meng Chew and bachelor degree from Dalian University of Technology. He joined Volkswagen Group ML Research Lab in November 2016. Interests representation learning metric learning robotics movement modeling","tags":"team","url":"https://argmax.ai/team/nutan-chen/"},{"title":"Patrick van der Smagt","text":"Patrick van der Smagt is director of the open-source Volkswagen Group Machine Learning Research Lab in Munich, focussing on probabilistic deep learning for time series modelling, optimal control, reinforcement learning robotics, and quantum machine learning. He previously directed a lab as professor for machine learning and biomimetic robotics at the Technical University of Munich while leading the machine learning group at the research institute fortiss, and before founded and headed the Assistive Robotics and Bionics Lab at the DLR Oberpfaffenhofen. Quite a bit earlier, he did his PhD and MSc at Amsterdam's universities. Besides publishing numerous papers and patents on machine learning, robotics, and motor control, he has won a number of awards, including the 2013 Helmholtz-Association Erwin Schrödinger Award, the 2014 King-Sun Fu Memorial Award, the 2013 Harvard Medical School/MGH Martin Research Prize, the 2018 Webit Best Implementation of AI Award, and best-paper awards at machine learning and robotics conferences and journals. Patrick reviews for governmental funding organisations and serve[ds] on conference and journal boards. He is founding chairman of a non-for-profit organisation for Assistive Robotics for tetraplegics and co-founder of various tech companies. Interests machine learning neural networks optimisation robotics computational neuroscience biomechanics brain-machine interfaces Google Scholar Linkedin","tags":"team","url":"https://argmax.ai/team/patrick-van-der-smagt/"},{"title":"Philip Becker-Ehmck","text":"Philip Becker-Ehmck joined Volkswagen Group ML Research Lab in August 2017. Prior to joining, he received his Bachelor and Master of Science degree in computer science from the Technical University of Munich. His Master's thesis was focused on learning latent space dynamics via intrinsically motivated exploration. For his PhD, Philip is working on learning more meaningful and hierarchical latent state space representations in particular for physical systems. Interests Probabilistic Sequence Models Intrinsic Motivation Model-based Reinforcement Learning Variational Inference","tags":"team","url":"https://argmax.ai/team/philip-becker-ehmck/"},{"title":"Rahul Banerjee","text":"Rahul is currently pursuing his Master's degree in Computatinal Science and Engineering from the Tehnical University of Munich. Originally from a mathematics-centered engineering background, his interest in machine learning techniques was kindled in courses on computer vision during his Master's and has been studying/working in various ML sub-domains ever since. Interests Deep Learning Graphical Models Computer Vision Information Geometry Mathematical Modelling","tags":"team","url":"https://argmax.ai/team/rahul-banerjee/"},{"title":"Richard Kurle","text":"Richard has completed a master's degree in Electrical and Computer Engineering at TU Munich. He completed his master's thesis with the Volkswagen Electronic Research Lab, where he worked on an end-to-end learning approach for autonomous driving. He is currently pursuing a PHD, focusing on multi-source and lifelong learning. Interests multi-source learning lifelong learning approximate inference in deep latent-variable models","tags":"team","url":"https://argmax.ai/team/richard-kurle/"},{"title":"Rotem Mordoch","text":"Rotem is a master's student for Informatics at the Technical University of Munich. During her studies she focused on machine learning and computer vision. She joined Volkswagen AI research in March 2018 to write her master's thesis. The thesis topic is Reinforcement Learning for Meta Learning, in which she ses a meta learner to predict optimal structures of Neural Networks and Probabilistic Graphical Models. Interests robotic vision variational inference natural language processing","tags":"team","url":"https://argmax.ai/team/rotem-mordoch/"},{"title":"Simon Klotz","text":"Simon is a student at the Technical University of Munich doing his Master in Data Engineering and Analytics. He joined the ML Research Lab in May 2019 to write his Master's thesis in which he applies sequence models to anomaly detection problems. Interests probabilistic sequence models variational inference anomaly detection","tags":"team","url":"https://argmax.ai/team/simon-klotz/"},{"title":"Weijie Zhang","text":"Interests model-based reinforcement learning dynamic movement primitives","tags":"team","url":"https://argmax.ai/team/weijie-zhang/"},{"title":"Yuriy Arabskyy","text":"Yuriy is a computer science student at the Technical University of Munich. He joined Volkswagen AI research in March 2018 to write his bachelor's thesis. His topic is \"Electromyography-based Robot Arm Control\". Interests Bayesian machine learning sequence modeling reinforcement learning","tags":"team","url":"https://argmax.ai/team/yuriy-arabskyy/"}]}